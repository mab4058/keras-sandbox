'''
Helper module for testing out models.

@author: mbayer
'''
from keras.callbacks import CSVLogger
from keras.models import model_from_yaml, model_from_json
from keras.preprocessing.image import ImageDataGenerator 
from keras.utils import np_utils


def modelTrainer(dataset='mnist', 
                 model_file=None, 
                 model_instance=None, 
                 batch_size=32, 
                 nb_epochs=100, 
                 data_augmentation=False, 
                 **kwargs):
    """
    Model trainer using some of Keras' built-in datasets. 
    
    # Arguments
        dataset: str, The dataset to use.
        model_file: str, Path to a model file saved as eithe .json or .yaml
        model_instance: instance, A compiled model instance.
        batch_size: int, number of samples in a mini-batch.
        nb_epochs: int, Number of passes through all the data.
        data_augmentation: bool, Set to true to use kwargs.
        kwargs: Any keyword argument for Keras data augmentation.
    # Returns
        None
    """
    
    if dataset == 'mnist':
        from keras.datasets import mnist
        (X_train, y_train), (X_test, y_test) = mnist.load_data()
        logger = CSVLogger('mnist_training_log.csv')
        nb_classes = 10
    elif dataset == 'cifar10':
        from keras.datasets import cifar10
        (X_train, y_train), (X_test, y_test) = cifar10.load_data()
        logger = CSVLogger('cifar10_training_log.csv')
        nb_classes = 10
    elif dataset == 'cifar100':
        from keras.datasets import cifar100
        (X_train, y_train), (X_test, y_test) = cifar100.load_data()
        logger = CSVLogger('cifar100_training_log.csv')
        nb_classes = 100
        
    print('X_train shape:', X_train.shape)
    print(X_train.shape[0], 'train samples')
    print(X_test.shape[0], 'test samples')
    
    
    if model_file is not None:
        model = loadModel(model_file)
    elif model_instance is not None:
        model = model_instance
        
    # Convert class vectors to binary class matrices.
    Y_train = np_utils.to_categorical(y_train, nb_classes)
    Y_test = np_utils.to_categorical(y_test, nb_classes)    
    
    # Let's train the model using RMSprop
    model.compile(loss='categorical_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
    
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255
    
    if not data_augmentation:
        print('Not using data augmentation.')
        model.fit(X_train, Y_train,
                  batch_size=batch_size,
                  nb_epoch=nb_epochs,
                  validation_data=(X_test, Y_test),
                  shuffle=True,
                  callbacks=[logger])
    else:
        print('Using real-time data augmentation.')
        # This will do preprocessing and realtime data augmentation:
        datagen = ImageDataGenerator(**kwargs)
    
        # Compute quantities required for featurewise normalization
        # (std, mean, and principal components if ZCA whitening is applied).
        datagen.fit(X_train)
            
        # Fit the model on the batches generated by datagen.flow().
        model.fit_generator(datagen.flow(X_train, Y_train,
                                         batch_size=batch_size),
                            steps_per_epoch=int(X_train.shape[0] / batch_size),
                            epochs=nb_epochs,
                            validation_data=(X_test, Y_test),
                            callbacks=[logger])
    
    
def loadModel(filename):
    parts = filename.split('.')
    if parts[1].lower() == 'json':
        model = _loadModelDefJson(filename)
    else:
        model = _loadModelDefYaml(filename)
        
    return model

def _loadModelDefYaml(filename):
    with open(filename, 'r') as f:
        model = model_from_yaml(f.read())  
    return model

def _loadModelDefJson(filename):
    with open(filename, 'r') as f:
        model = model_from_json(f.read())  
    return model

if __name__ == '__main__':
    pass
